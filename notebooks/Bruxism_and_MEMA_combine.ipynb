{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Trial to combine middle ear and bruxism tagging to identify pure moments of middle ear activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = os.getcwd() \n",
    "import sys\n",
    "sys.path.append(PATH + '/../')\n",
    "import mne\n",
    "from tinnsleep.config import Config\n",
    "from tinnsleep.create_reports import preprocess, reporting, combine_brux_MEMA\n",
    "from tinnsleep.data import CreateRaw, RawToEpochs_sliding, CleanAnnotations, AnnotateRaw_sliding\n",
    "from tinnsleep.classification import AmplitudeThresholding\n",
    "from tinnsleep.check_impedance import create_annotation_mne, Impedance_thresholding_sliding, check_RMS, fuse_with_classif_result\n",
    "from tinnsleep.signal import rms\n",
    "from tinnsleep.scoring import classif_to_burst, burst_to_episode, create_list_events, generate_bruxism_report, generate_MEMA_report\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from tinnsleep.config import Config\n",
    "\n",
    "print(\"Config loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting down parameters for MEMA detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMA parameters set\n",
      "['1DA15_nuit_son.edf' '1GB19_nuit_hab.edf' '1MF19_nuit_hab.edf']\n"
     ]
    }
   ],
   "source": [
    "#Setting MEMA parameters\n",
    "EDF_list = Config.bruxisme_files\n",
    "THR_classif_MEMA=[[0,3.5]]\n",
    "sfreq = 250.0\n",
    "window_length_MEMA = 1.00                    # in seconds\n",
    "duration_MEMA = int(window_length_MEMA * sfreq)   # in samples\n",
    "interval_MEMA = duration_MEMA                  # no overlapping\n",
    "n_adaptive_MEMA = -60/window_length_MEMA          # number of epochs for adaptive baseline\n",
    "delim_MEMA = 3                               # maximal time interval between bursts to merge episode in seconds\n",
    "\n",
    "# Dictionnary of known names of the Airflow\n",
    "mapping = {\"Airflow\": \"MEMA\"}\n",
    "print(\"MEMA parameters set\")\n",
    "min_burst_joining_MEMA = 0\n",
    "\n",
    "mema_files = pd.read_csv(\"data/mema_files.csv\",engine='python', sep=\"; \")[\"files_with_mema\"].values\n",
    "print(mema_files[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting down parameters for bruxism detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bruxism parameters set\n"
     ]
    }
   ],
   "source": [
    "#Setting parameters\n",
    "os.chdir(\"C:/Users/Zeta/Documents/acou_sommeil_HD_ENS/Tinnitus-n-Sleep/Notebooks\")\n",
    "THR_classif_brux=[[0,2]]\n",
    "sfreq = 250\n",
    "window_length_brux = 0.25                    # in seconds\n",
    "duration_brux = int(window_length_brux * sfreq)   # in samples\n",
    "interval_brux = duration_brux                     # no overlapping\n",
    "n_adaptive_brux = 480 # number of epochs for adaptative baseline\n",
    "\n",
    "#Importing personnalized parameters for dataset\n",
    "df = pd.read_pickle(\"data/valid_chans_THR_imp.pk\")\n",
    "dico_chans= df.to_dict(\"list\")\n",
    "min_burst_joining_brux = 3\n",
    "delim_brux =3\n",
    "print(\"Bruxism parameters set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bruxism + MEMA processing for pure MEMA visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed : \n",
      "sophie_mema.edf sophie_mema.edf preprocess... DONE (9.98s) report... bruxsim processing DONE (10.77s)\n",
      "preprocess...DONE (0.78s) report...Mema processing DONE (5.11s)\n",
      "Raw annotated\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "# load file from config\n",
    "filenames=['E:/Acou_sommeil/EDF_V2_PAUL\\\\sophie_mema.edf']\n",
    "\n",
    "#Output of the processing, stock pure MEMA analysis output\n",
    "\n",
    "results_MEMA={}\n",
    "results_brux={}\n",
    "\n",
    "start = time()\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    print(\"Files processed : \")\n",
    "    \n",
    "    #Loop on all the patient files\n",
    "    for filename in filenames:\n",
    "        #opens the raw file\n",
    "        file = filename.split(os.path.sep)[-1]\n",
    "        print(file, end=\" \")\n",
    "        if not file in mema_files:\n",
    "            print(f\"not included\")\n",
    "        else:\n",
    "            #opens the raw file\n",
    "            raw = mne.io.read_raw_edf(filename, preload=False, verbose=False)  # prepare loading\n",
    "            raw.rename_channels(mapping=mapping)\n",
    "            file = filename.split(os.path.sep)[-1]\n",
    "            print(file, end=\" \")\n",
    "            #Get channels indexes\n",
    "            ind_picks_chan= dico_chans[file][0]\n",
    "            ind_picks_imp= dico_chans[file][1]\n",
    "            #Get THR_imp value for filename\n",
    "            THR_imp = dico_chans[file][2]\n",
    "\n",
    "            #Get channel names from indexes\n",
    "            if len(ind_picks_chan)>0: #ignore file if no channel is good\n",
    "                picks_chan=[]\n",
    "                for elm in ind_picks_chan:\n",
    "                    picks_chan.append(raw.info[\"ch_names\"][elm])\n",
    "                picks_imp=[]\n",
    "                for elm in ind_picks_imp:\n",
    "                    picks_imp.append(raw.info[\"ch_names\"][elm])\n",
    "                #Setting parameters for is_good\n",
    "                params = dict(ch_names=picks_chan,\n",
    "                      rejection_thresholds=dict(emg=5e-04),  # two order of magnitude higher q0.01\n",
    "                      flat_thresholds=dict(emg=1e-09),  # one order of magnitude lower median\n",
    "                      channel_type_idx=dict(emg=[ i for i in range(len(picks_chan))]),\n",
    "                      full_report=True\n",
    "                      )\n",
    "                # Get the preprocessing steps done\n",
    "                print(\"preprocess...\", end=\" \");tmp = time()\n",
    "                epochs, valid_labels_brux, log = preprocess(raw, picks_chan, picks_imp, duration_brux, interval_brux, params, THR_imp=THR_imp, get_log=True)\n",
    "                print(f\"DONE ({time()-tmp:.2f}s)\", end=\" \")\n",
    "                #If at least one epoch is good create report\n",
    "                print(\"report...\", end=\" \");tmp = time()\n",
    "                if np.sum(valid_labels_brux)>0 :\n",
    "                    results_brux[filename] = reporting(epochs, valid_labels_brux, THR_classif_brux, time_interval=window_length_brux, delim=delim_brux, n_adaptive = n_adaptive_brux, log=log, generate_report=generate_bruxism_report)\n",
    "                    print(f\"bruxsim processing DONE ({time()-tmp:.2f}s)\")\n",
    "                    \n",
    "                     \n",
    "                   \n",
    "                    \n",
    "\n",
    "                    picks_chan_user= ['MEMA']  # could be remplaced by an user-specific list loaded from .pk\n",
    "                    ch_types = \"misc\"\n",
    "                    #check if channels exists\n",
    "                    picks_chan = [];[picks_chan.append(ch) for ch in picks_chan_user if ch in raw.info[\"ch_names\"]]\n",
    "\n",
    "                    #Get channel names from indexes\n",
    "                    if len(picks_chan)>0: #ignore file if no channel is good\n",
    "\n",
    "                        #-----------------MEMA processing preparation ---------------------------------------\n",
    "                        print(\"preprocess...\", end=\"\");tmp = time()\n",
    "                        raw = CreateRaw(raw[picks_chan][0], raw.info[\"sfreq\"], picks_chan, ch_types=ch_types)  # pick channels and load\n",
    "                        epochs = RawToEpochs_sliding(raw, duration=duration_MEMA, interval=interval_MEMA, picks=picks_chan)\n",
    "                        print(f\"DONE ({time()-tmp:.2f}s)\", end=\" \")\n",
    "                        valid_labels_MEMA = [True] * epochs.shape[0] # consider all valid epochs\n",
    "                        print(\"report...\", end=\"\");tmp = time()\n",
    "                        results_MEMA[filename] = reporting(epochs, valid_labels_MEMA, THR_classif_MEMA, time_interval=window_length_MEMA, delim=delim_MEMA, n_adaptive=n_adaptive_MEMA, generate_report=generate_MEMA_report)\n",
    "                        print(f\"Mema processing DONE ({time()-tmp:.2f}s)\")\n",
    "                       \n",
    "                        \n",
    "                        \n",
    "\n",
    "\n",
    "                        brux_comb_ep, brux_pure_ep, compt_arti_brux, MEMA_comb_ep, MEMA_pure_ep, compt_arti_MEMA = combine_brux_MEMA \\\n",
    "                        (results_brux[filename][\"labels\"][0], valid_labels_brux, window_length_brux, delim_brux, results_MEMA[filename][\"labels\"][0],\n",
    "                         valid_labels_MEMA,\n",
    "                         window_length_MEMA, delim_MEMA,\n",
    "                         min_burst_joining_brux=0, min_burst_joining_MEMA=0)\n",
    "\n",
    "                        pure_brux_bursts = classif_to_burst(brux_pure_ep, time_interval=window_length_brux)\n",
    "                        li_ep_brux_p = burst_to_episode(pure_brux_bursts, delim=delim_brux, min_burst_joining= min_burst_joining_brux)\n",
    "                        pure_brux_events = create_list_events(li_ep_brux_p, window_length_brux, len(brux_pure_ep) * window_length_brux)\n",
    "\n",
    "                        comb_brux_bursts = classif_to_burst(brux_comb_ep, time_interval=window_length_brux)\n",
    "                        li_ep_brux_c = burst_to_episode(comb_brux_bursts, delim=delim_brux, min_burst_joining= min_burst_joining_brux)\n",
    "                        comb_brux_events = create_list_events(li_ep_brux_c, window_length_brux, len(brux_comb_ep) * window_length_brux)\n",
    "\n",
    "                        for i in range(len(MEMA_comb_ep)):\n",
    "                            if MEMA_comb_ep[i]>0:\n",
    "                                MEMA_comb_ep[i]+=3\n",
    "                                \n",
    "                        #-----------------Pure MEMA episodes visualisation and comparison with ATM activity -----------------------------------\n",
    "                        #Preparing raw for visualisation\n",
    "                        picks_chan = ['Airflow', '1', '2']           # subset of EMG electrodes\n",
    "                        raw  = mne.io.read_raw_edf(filename, preload=False, verbose=False)  # prepare loading\n",
    "                        raw  = CreateRaw(raw[picks_chan][0], raw.info[\"sfreq\"], picks_chan, ch_types='emg')        # pick channels and load\n",
    "                        raw  = raw.load_data()\n",
    "                        dat=raw.get_data()\n",
    "                        dat[1]=[dat[1][i]*1/(0.0005) for i in range(len(dat[1]))]\n",
    "                        dat[2]=[dat[2][i]*1/(0.0005) for i in range(len(dat[2]))]\n",
    "                        raw  = CreateRaw(dat, raw.info[\"sfreq\"], picks_chan, ch_types='emg') \n",
    "\n",
    "                        raw  = raw.filter(20., 99., n_jobs=4, \n",
    "                                          fir_design='firwin', filter_length='auto', phase='zero-double',\n",
    "                                          picks=['1', '2'])\n",
    "\n",
    "                        #Annotating the raw\n",
    "                        raw = CleanAnnotations(raw)\n",
    "                        dict_annotations = {1: \"pure\", 4:\"comb\", 3:\"mixed\"}\n",
    "                        raw = AnnotateRaw_sliding(raw, MEMA_comb_ep , \n",
    "                                        dict_annotations=dict_annotations, duration=duration_brux, interval=interval_brux)\n",
    "\n",
    "                        raw = AnnotateRaw_sliding(raw, comb_brux_events , \n",
    "                                        dict_annotations=dict_annotations, duration=duration_brux, interval=interval_brux)\n",
    "                        print(\"Raw annotated\")\n",
    "                        raw.plot(scalings = \"auto\")\n",
    "                        plt.title(filename)\n",
    "\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small function to check if all channel selections are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed : \n",
      "1BA07_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1BA07_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1CC05_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1CC05_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1DA15_nuit_hab.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "1DA15_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1DL12_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1DL12_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1GB18_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1GB19_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1GF14_nuit_hab.edf\n",
      "1GF14_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MA16_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MA16_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MF19_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MF19_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1MN09_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MN09_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1PI07_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1PI07_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1PT06_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1PT06_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1RA17_nuit_hab.edf\n",
      "1RA17_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1SA14_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1SA14_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1ZN04_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1ZN04_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "HZB_nuit_1.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "HZB_nuit_2.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "HZB_nuit_3.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "SCHMIDTLIN_nuit_1_dec_OD__0to0.edf\n",
      "SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "SCHMIDTLIN_nuit_4_dec_OD__3to3.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "SCHMIDTLIN_nuit_5_dec_OD__0to1.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "SCHM_nuit_1.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "SCHM_nuit_2.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "SCHM_nuit_3.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "Schmidtlin_nuit_2_dec_3to0to4.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "Unger_2.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "jon_mema.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "jose_mema.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "robin_mema_nuit_1.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "robin_mema_nuit_2.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "robin_nuit_23_sept.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "robin_nuit_son_24_sept.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "sophie_mema.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "tom_mema.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "unger_nuit_1.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "labels_subj={}\n",
    "EDF_list = Config.bruxisme_files\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    results={}\n",
    "    print(\"Files processed : \")\n",
    "    for filename in EDF_list:\n",
    "        #opens the raw file\n",
    "        raw = mne.io.read_raw_edf(filename, preload=False, verbose=False)  # prepare loading\n",
    "        print(filename.split(\"\\\\\")[-1])\n",
    "        #Get channels indexes\n",
    "        ind_picks_chan= dico_chans[filename.split(\"\\\\\")[-1]][0]\n",
    "        ind_picks_imp= dico_chans[filename.split(\"\\\\\")[-1]][1]\n",
    "        #Get THR_imp value for filename\n",
    "        THR_imp = dico_chans[filename.split(\"\\\\\")[-1]][2]\n",
    "        #print(raw.info[\"ch_names\"])\n",
    "        #Get channel names from indexes\n",
    "        if len(ind_picks_chan)>0: #ignore file if no channel is good\n",
    "            picks_chan=[]\n",
    "            for elm in ind_picks_chan:\n",
    "                picks_chan.append(raw.info[\"ch_names\"][elm])\n",
    "            picks_imp=[]\n",
    "            for elm in ind_picks_imp:\n",
    "                picks_imp.append(raw.info[\"ch_names\"][elm])\n",
    "            print(picks_chan)\n",
    "            print(picks_imp)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
