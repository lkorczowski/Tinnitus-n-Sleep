{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Trial to combine middle ear and bruxism tagging to identify pure moments of middle ear activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = os.getcwd() \n",
    "import sys\n",
    "sys.path.append(PATH + '/../')\n",
    "import mne\n",
    "from tinnsleep.config import Config\n",
    "from tinnsleep.create_reports import preprocess, reporting\n",
    "from tinnsleep.data import CreateRaw, RawToEpochs_sliding, CleanAnnotations, AnnotateRaw_sliding\n",
    "from tinnsleep.classification import AmplitudeThresholding\n",
    "from tinnsleep.check_impedance import create_annotation_mne, Impedance_thresholding_sliding, check_RMS, fuse_with_classif_result\n",
    "from tinnsleep.signal import rms\n",
    "from tinnsleep.scoring import classif_to_burst, burst_to_episode, create_list_events\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from tinnsleep.config import Config\n",
    "\n",
    "print(\"Config loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:/Acou_sommeil/EDF_V2_PAUL\\\\robin_nuit_23_sept.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\robin_nuit_son_24_sept.edf']\n",
      "\n",
      "['E:/Acou_sommeil/EDF_V2_PAUL\\\\1DA15_nuit_son.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\1GB19_nuit_hab.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\1MF19_nuit_hab.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\1RA17_nuit_hab.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\HZB_nuit_1.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\HZB_nuit_2.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\HZB_nuit_3.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHMIDTLIN_nuit_1_dec_OD__0to0.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHMIDTLIN_nuit_4_dec_OD__3to3.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHMIDTLIN_nuit_5_dec_OD__0to1.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHM_nuit_1.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHM_nuit_2.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHM_nuit_3.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\Schmidtlin_nuit_2_dec_3to0to4.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\Unger_2.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\jon_mema.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\jose_mema.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\robin_mema_nuit_1.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\robin_mema_nuit_2.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\sophie_mema.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\tom_mema.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\unger_nuit_1.edf']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#List of MEMA files, hardcoded, to be modified\n",
    "print(Config.bruxisme_files[44:46])\n",
    "print(\"\")\n",
    "ME_files=[Config.bruxisme_files[5], Config.bruxisme_files[9], \n",
    "          Config.bruxisme_files[14], Config.bruxisme_files[22]]\n",
    "ME_files.extend(Config.bruxisme_files[28:44])\n",
    "ME_files.extend(Config.bruxisme_files[46:])\n",
    "\n",
    "print(ME_files)\n",
    "print(len(ME_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting down parameters for bruxism detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters set\n"
     ]
    }
   ],
   "source": [
    "#Setting parameters\n",
    "os.chdir(\"C:/Users/Zeta/Documents/acou_sommeil_HD_ENS/Tinnitus-n-Sleep/Notebooks\")\n",
    "THR_classif=[[0,2]]\n",
    "sfreq = 200\n",
    "window_length = 0.25                    # in seconds\n",
    "duration = int(window_length * sfreq)   # in samples\n",
    "interval = duration                     # no overlapping\n",
    "n_adaptive = 480 # number of epochs for adaptative baseline\n",
    "\n",
    "#Importing personnalized parameters for dataset\n",
    "df = pd.read_pickle(\"data/valid_chans_THR_imp.pk\")\n",
    "dico_chans= df.to_dict(\"list\")\n",
    "print(\"parameters set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bruxism + MEMA processing for pure MEMA visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed : \n",
      "sophie_mema.edf\n",
      "['2']\n",
      "Bruxism reporting done\n",
      "Data filtered\n",
      "Epochs done, shape (31625, 1, 200)\n",
      "number of middle ear events\n",
      "130\n",
      "Raw annotated\n",
      "tom_mema.edf\n",
      "['2']\n",
      "Bruxism reporting done\n",
      "Data filtered\n",
      "Epochs done, shape (31562, 1, 200)\n",
      "number of middle ear events\n",
      "89\n",
      "Raw annotated\n",
      "unger_nuit_1.edf\n",
      "['1', '2']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b51ee1c5f2c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;31m# Get the preprocessing steps done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             epochs, valid_labels, log = preprocess(raw, picks_chan, picks_imp, duration, interval, \n\u001b[1;32m---> 51\u001b[1;33m                                                    params, THR_imp=THR_imp, get_log=True)\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;31m#If at least one epoch is good create report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreporting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTHR_classif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_adaptive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\acou_sommeil_HD_ENS\\Tinnitus-n-Sleep\\notebooks/..\\tinnsleep\\create_reports.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(raw, picks_chan, picks_imp, duration, interval, params, THR_imp, get_log, filter)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# Epoch rejection based on impedance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mcheck_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImpedance_thresholding_sliding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpicks_imp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTHR\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTHR_imp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mimpedance_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_imp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0msuppressed_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimpedance_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mne\\io\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m             data = self._read_segment(start=start, stop=stop, sel=sel,\n\u001b[1;32m--> 732\u001b[1;33m                                       projector=self._projector)\n\u001b[0m\u001b[0;32m    733\u001b[0m         \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-148>\u001b[0m in \u001b[0;36m_read_segment\u001b[1;34m(self, start, stop, sel, data_buffer, projector, verbose)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mne\\io\\base.py\u001b[0m in \u001b[0;36m_read_segment\u001b[1;34m(self, start, stop, sel, data_buffer, projector, verbose)\u001b[0m\n\u001b[0;32m    385\u001b[0m             self._read_segment_file(data[:, this_sl], idx, fi,\n\u001b[0;32m    386\u001b[0m                                     \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m                                     cals, mult)\n\u001b[0m\u001b[0;32m    388\u001b[0m             \u001b[0moffset\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn_read\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mne\\io\\edf\\edf.py\u001b[0m in \u001b[0;36m_read_segment_file\u001b[1;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[0;32m    138\u001b[0m         return _read_segment_file(data, idx, fi, start, stop,\n\u001b[0;32m    139\u001b[0m                                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_extras\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                                   self._filenames[fi])\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mne\\io\\edf\\edf.py\u001b[0m in \u001b[0;36m_read_segment_file\u001b[1;34m(data, idx, fi, start, stop, raw_extras, chs, filenames)\u001b[0m\n\u001b[0;32m    310\u001b[0m                             npad=0, axis=-1)\n\u001b[0;32m    311\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mch_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_sidx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0md_eidx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mch_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr_sidx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mr_eidx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;31m# only try to read the stim channel if it's not None and it's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filenames = ME_files[-3:]  # load file from config\n",
    "#filenames=['E:/Acou_sommeil/EDF_V2_PAUL\\\\sophie_mema.edf']\n",
    "\n",
    "#Output of the processing, stock pure MEMA analysis output\n",
    "ME_reports={}\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    print(\"Files processed : \")\n",
    "    \n",
    "    #Loop on all the patient files\n",
    "    for filename in filenames:\n",
    "        \n",
    "        #-----------------Preparation for bruxism  processing ---------------------------------------\n",
    "        #opens the raw file\n",
    "        raw = mne.io.read_raw_edf(filename, preload=False, verbose=False)  # prepare loading\n",
    "        print(filename.split(\"\\\\\")[-1])\n",
    "        #Get channels indexes\n",
    "        ind_picks_chan= dico_chans[filename.split(\"\\\\\")[-1]][0]\n",
    "        ind_picks_imp= dico_chans[filename.split(\"\\\\\")[-1]][1]\n",
    "        #Get THR_imp value for filename\n",
    "        THR_imp = dico_chans[filename.split(\"\\\\\")[-1]][2]\n",
    "        #Get channel names from indexes\n",
    "        if len(ind_picks_chan)>0: #ignore file if no channel is good\n",
    "            picks_chan=[]\n",
    "            for elm in ind_picks_chan:\n",
    "                picks_chan.append(raw.info[\"ch_names\"][elm])\n",
    "            picks_imp=[]\n",
    "            for elm in ind_picks_imp:\n",
    "                picks_imp.append(raw.info[\"ch_names\"][elm])\n",
    "            print(picks_chan)\n",
    "            #Setting parameters for is_good\n",
    "            params = dict(ch_names=picks_chan,\n",
    "                  rejection_thresholds=dict(emg=1e-04),  # two order of magnitude higher q0.01\n",
    "                  flat_thresholds=dict(emg=1e-09),  # one order of magnitude lower median\n",
    "                  channel_type_idx=dict(emg=[ i for i in range(len(picks_chan))]),\n",
    "                  full_report=True\n",
    "                  )\n",
    "            #Epoching parameters\n",
    "            window_length = 0.25                    # in seconds\n",
    "            duration = int(window_length * sfreq)   # in samples\n",
    "            interval = duration                     # no overlapping\n",
    "            \n",
    "            \n",
    "            #-----------------Bruxism  processing ---------------------------------------\n",
    "            # Get the preprocessing steps done\n",
    "            epochs, valid_labels, log = preprocess(raw, picks_chan, picks_imp, duration, interval, \n",
    "                                                   params, THR_imp=THR_imp, get_log=True)\n",
    "            if np.sum(valid_labels)>0 : #If at least one epoch is good create report\n",
    "                results[filename] = reporting(epochs, valid_labels, THR_classif, n_adaptive, log)\n",
    "                #List of labels for MEMA processing crossing\n",
    "                bruxism = results[filename][\"labels\"][0]\n",
    "                artefacts = valid_labels\n",
    "            \n",
    "                print(\"Bruxism reporting done\")\n",
    "\n",
    "                #-----------------MEMA processing preparation ---------------------------------------\n",
    "                picks_chan = ['Airflow']           # middle ear electrode\n",
    "                raw  = CreateRaw(raw[picks_chan][0], picks_chan, ch_types=['emg']) # pick channels and load\n",
    "                ch_names = raw.info[\"ch_names\"]\n",
    "                print(\"Data filtered\")\n",
    "\n",
    "                #epoching\n",
    "                sfreq = raw.info[\"sfreq\"]\n",
    "                window_length = 1                    # in seconds\n",
    "                duration = int(window_length * sfreq)   # in samples\n",
    "                interval = duration                     # no overlapping\n",
    "                epochs = RawToEpochs_sliding(raw, duration=duration, interval=interval)\n",
    "                print(f\"Epochs done, shape {epochs.shape}\")\n",
    "\n",
    "                #-----------------MEMA processing Foward-backward ---------------------------------------\n",
    "                #Foward\n",
    "                # compute the sum of power over electrodes and samples in each window\n",
    "                pipeline = AmplitudeThresholding(abs_threshold=0., rel_threshold=4, n_adaptive=60)\n",
    "                X        = rms(epochs) # take only valid labels\n",
    "                labels_f   = pipeline.fit_predict(X)\n",
    "\n",
    "\n",
    "                #Backward\n",
    "                #Reversing epochs array\n",
    "                epochs = epochs[::-1]\n",
    "                 # compute the sum of power over electrodes and samples in each window\n",
    "                pipeline = AmplitudeThresholding(abs_threshold=0., rel_threshold=4, n_adaptive=60)\n",
    "                X        = rms(epochs) # take only valid labels\n",
    "                labels   = pipeline.fit_predict(X)\n",
    "                #Reversing labels\n",
    "                labels_b = labels[::-1]\n",
    "                \n",
    "                \n",
    "                #-----------------MEMA foward-backward merge ---------------------------------------\n",
    "                # Logical OR -- merged backward and foward\n",
    "                labels_fb = np.any(np.c_[labels_f, labels_b], axis=-1)\n",
    "                 \n",
    "                \n",
    "                #-----------------MEMA / bruxism merge preparation---------------------------------------\n",
    "                #adaptation of labels_fb from 1s epochs to 0,25s epochs\n",
    "                labels_fb_shep=[]  \n",
    "                for elm in labels_fb:\n",
    "                    for i in range(4):\n",
    "                        labels_fb_shep.append(elm)\n",
    "                        \n",
    "                        \n",
    "                #Creation of the list of episodes from the labels list of bruxism:\n",
    "                burst_list = classif_to_burst(bruxism, time_interval=0.25)\n",
    "                li_ep = burst_to_episode(burst_list, delim=3)\n",
    "                event_list = create_list_events(li_ep, 0.25, len(bruxism) * 0.25)\n",
    "                #Careful, len(labels_fb_shep) and len(bruxism) maybe different by 1, 2 or 3 due to rounding effects.\n",
    "                \n",
    "\n",
    "                #enlarge bruxism episodes on sides by 4 epochs:\n",
    "                if event_list[0]==0:\n",
    "                    flag = False\n",
    "                else:\n",
    "                    flag = True\n",
    "                for i in range(len(event_list)-4):\n",
    "                    if not flag :\n",
    "                        if not event_list[i+4] == 0:\n",
    "                            for j in range(4):\n",
    "                                event_list[i+j]=4\n",
    "                            flag = True\n",
    "                    if flag : \n",
    "                        if event_list[i+1] == 0:\n",
    "                            for j in range(4):\n",
    "                                event_list[i+j+1]=4\n",
    "                            flag = False\n",
    "                            \n",
    "                #enlarge bruxism bursts on sides by 2 epochs:\n",
    "                if bruxism[0]==0:\n",
    "                    flag = False\n",
    "                else:\n",
    "                    flag = True\n",
    "                for i in range(len(bruxism)-2):\n",
    "                    if not flag :\n",
    "                        if not bruxism[i+2] == 0:\n",
    "                            for j in range(2):\n",
    "                                bruxism[i+j]=True\n",
    "                            flag = True\n",
    "                    if flag : \n",
    "                        if bruxism[i+1] == 0:\n",
    "                            for j in range(2):\n",
    "                                bruxism[i+j+1]=True\n",
    "                            flag = False\n",
    "\n",
    "                #-----------------MEMA / bruxism merge to obtain Pure MEMA -----------------------------------------------\n",
    "                #merge MEMA and compare with bruxism and artefacts\n",
    "                for i in range(len(bruxism)):\n",
    "                    if i < len(labels_fb_shep) - 1 : #len(labels_fb_shep) and len(bruxism) may be different by 1, 2 or 3\n",
    "                        if bruxism[i]:\n",
    "                            labels_fb_shep[i] = False\n",
    "                        if not artefacts[i]:\n",
    "                            labels_fb_shep[i] = False\n",
    "                        if not event_list[i] == 0:\n",
    "                            labels_fb_shep[i] = False\n",
    "\n",
    "                \n",
    "                #-----------------Pure MEMA bursts conversion to episodes ----------------------------------------\n",
    "                OM_burst = classif_to_burst(labels_fb_shep, time_interval=0.25)\n",
    "                OM_ep= burst_to_episode(OM_burst, delim=1.5, min_burst_joining=0)\n",
    "                li_OM = create_list_events(OM_ep, 0.25, 0.25* len(bruxism))\n",
    "\n",
    "                #All episodes as tonic\n",
    "                for elm in li_OM:\n",
    "                    if elm!=0:\n",
    "                        elm=True\n",
    "                    else:\n",
    "                        elm = False\n",
    "\n",
    "                #Should work without these lines since episode fix with min_burst_joining=0\n",
    "                miny = min(len(li_OM), len(labels_fb_shep))\n",
    "                MEMA = np.any(np.c_[li_OM[:miny], labels_fb_shep[:miny]], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "                print(\"number of middle ear events\")\n",
    "                print(len(OM_ep))\n",
    "                \n",
    "\n",
    "\n",
    "                #-----------------Pure MEMA episodes visualisation and comparison with ATM activity -----------------------------------\n",
    "                #Preparing raw for visualisation\n",
    "                picks_chan = ['Airflow', '1', '2']           # subset of EMG electrodes\n",
    "                raw  = mne.io.read_raw_edf(filename, preload=False, verbose=False)  # prepare loading\n",
    "                raw  = CreateRaw(raw[picks_chan][0], picks_chan, ch_types='emg')        # pick channels and load\n",
    "                raw  = raw.load_data()\n",
    "                dat=raw.get_data()\n",
    "                dat[1]=[dat[1][i]*1/(0.0005) for i in range(len(dat[1]))]\n",
    "                dat[2]=[dat[2][i]*1/(0.0005) for i in range(len(dat[2]))]\n",
    "                raw  = CreateRaw(dat, picks_chan, ch_types='emg') \n",
    "\n",
    "                raw  = raw.filter(20., 99., n_jobs=4, \n",
    "                                  fir_design='firwin', filter_length='auto', phase='zero-double',\n",
    "                                  picks=['1', '2'])\n",
    "                \n",
    "                #Annotating the raw\n",
    "                raw = CleanAnnotations(raw)\n",
    "                dict_annotations = {1: \"tot\"}\n",
    "                raw = AnnotateRaw_sliding(raw, MEMA, \n",
    "                                dict_annotations=dict_annotations, duration=50, interval=50)\n",
    "                print(\"Raw annotated\")\n",
    "                raw.plot(scalings = \"auto\")\n",
    "                plt.title(filename)\n",
    "                ME_reports[filename] = [MEMA, len(OM_ep), np.sum(MEMA)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Acou_sommeil/EDF_V2_PAUL\\1DA15_nuit_son.edf\n",
      "15\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\1GB19_nuit_hab.edf\n",
      "141\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\1MF19_nuit_hab.edf\n",
      "37\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\HZB_nuit_1.edf\n",
      "70\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\HZB_nuit_2.edf\n",
      "49\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\HZB_nuit_3.edf\n",
      "22\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf\n",
      "142\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHMIDTLIN_nuit_4_dec_OD__3to3.edf\n",
      "110\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHMIDTLIN_nuit_5_dec_OD__0to1.edf\n",
      "101\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHM_nuit_1.edf\n",
      "6\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHM_nuit_2.edf\n",
      "87\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHM_nuit_3.edf\n",
      "147\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\Schmidtlin_nuit_2_dec_3to0to4.edf\n",
      "0\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\Unger_2.edf\n",
      "272\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\jon_mema.edf\n",
      "182\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\jose_mema.edf\n",
      "29\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\robin_mema_nuit_1.edf\n",
      "78\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\robin_mema_nuit_2.edf\n",
      "166\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\sophie_mema.edf\n",
      "130\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\tom_mema.edf\n",
      "89\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\unger_nuit_1.edf\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "for elm in ME_reports.keys():\n",
    "    print(elm)\n",
    "    print(ME_reports[elm][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small function to check if all channel selections are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed : \n",
      "1BA07_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1BA07_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1CC05_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1CC05_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1DA15_nuit_hab.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "1DA15_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1DL12_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1DL12_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1GB18_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1GB19_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1GF14_nuit_hab.edf\n",
      "1GF14_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MA16_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MA16_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MF19_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MF19_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1MN09_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MN09_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1PI07_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1PI07_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1PT06_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1PT06_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1RA17_nuit_hab.edf\n",
      "1RA17_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1SA14_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1SA14_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1ZN04_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1ZN04_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "HZB_nuit_1.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "HZB_nuit_2.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "HZB_nuit_3.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "SCHMIDTLIN_nuit_1_dec_OD__0to0.edf\n",
      "SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "SCHMIDTLIN_nuit_4_dec_OD__3to3.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "SCHMIDTLIN_nuit_5_dec_OD__0to1.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "SCHM_nuit_1.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "SCHM_nuit_2.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "SCHM_nuit_3.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "Schmidtlin_nuit_2_dec_3to0to4.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "Unger_2.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "jon_mema.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "jose_mema.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "robin_mema_nuit_1.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "robin_mema_nuit_2.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "robin_nuit_23_sept.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "robin_nuit_son_24_sept.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "sophie_mema.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "tom_mema.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "unger_nuit_1.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "labels_subj={}\n",
    "EDF_list = Config.bruxisme_files\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    results={}\n",
    "    print(\"Files processed : \")\n",
    "    for filename in EDF_list:\n",
    "        #opens the raw file\n",
    "        raw = mne.io.read_raw_edf(filename, preload=False, verbose=False)  # prepare loading\n",
    "        print(filename.split(\"\\\\\")[-1])\n",
    "        #Get channels indexes\n",
    "        ind_picks_chan= dico_chans[filename.split(\"\\\\\")[-1]][0]\n",
    "        ind_picks_imp= dico_chans[filename.split(\"\\\\\")[-1]][1]\n",
    "        #Get THR_imp value for filename\n",
    "        THR_imp = dico_chans[filename.split(\"\\\\\")[-1]][2]\n",
    "        #print(raw.info[\"ch_names\"])\n",
    "        #Get channel names from indexes\n",
    "        if len(ind_picks_chan)>0: #ignore file if no channel is good\n",
    "            picks_chan=[]\n",
    "            for elm in ind_picks_chan:\n",
    "                picks_chan.append(raw.info[\"ch_names\"][elm])\n",
    "            picks_imp=[]\n",
    "            for elm in ind_picks_imp:\n",
    "                picks_imp.append(raw.info[\"ch_names\"][elm])\n",
    "            print(picks_chan)\n",
    "            print(picks_imp)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
