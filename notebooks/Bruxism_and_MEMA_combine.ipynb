{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Trial to combine middle ear and bruxism tagging to identify pure moments of middle ear activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = os.getcwd() \n",
    "import sys\n",
    "sys.path.append(PATH + '/../')\n",
    "import mne\n",
    "from tinnsleep.config import Config\n",
    "from tinnsleep.create_reports import preprocess, reporting\n",
    "from tinnsleep.data import CreateRaw, RawToEpochs_sliding, CleanAnnotations, AnnotateRaw_sliding\n",
    "from tinnsleep.classification import AmplitudeThresholding\n",
    "from tinnsleep.check_impedance import create_annotation_mne, Impedance_thresholding_sliding, check_RMS, fuse_with_classif_result\n",
    "from tinnsleep.signal import rms\n",
    "from tinnsleep.scoring import classif_to_burst, burst_to_episode, create_list_events\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from tinnsleep.config import Config\n",
    "\n",
    "print(\"Config loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:/Acou_sommeil/EDF_V2_PAUL\\\\robin_nuit_23_sept.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\robin_nuit_son_24_sept.edf']\n",
      "\n",
      "['E:/Acou_sommeil/EDF_V2_PAUL\\\\1DA15_nuit_son.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\1GB19_nuit_hab.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\1MF19_nuit_hab.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\1RA17_nuit_hab.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\HZB_nuit_1.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\HZB_nuit_2.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\HZB_nuit_3.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHMIDTLIN_nuit_1_dec_OD__0to0.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHMIDTLIN_nuit_4_dec_OD__3to3.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHMIDTLIN_nuit_5_dec_OD__0to1.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHM_nuit_1.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHM_nuit_2.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\SCHM_nuit_3.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\Schmidtlin_nuit_2_dec_3to0to4.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\Unger_2.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\jon_mema.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\jose_mema.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\robin_mema_nuit_1.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\robin_mema_nuit_2.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\sophie_mema.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\tom_mema.edf', 'E:/Acou_sommeil/EDF_V2_PAUL\\\\unger_nuit_1.edf']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#List of MEMA files, hardcoded, to be modified\n",
    "print(Config.bruxisme_files[44:46])\n",
    "print(\"\")\n",
    "ME_files=[Config.bruxisme_files[5], Config.bruxisme_files[9], \n",
    "          Config.bruxisme_files[14], Config.bruxisme_files[22]]\n",
    "ME_files.extend(Config.bruxisme_files[28:44])\n",
    "ME_files.extend(Config.bruxisme_files[46:])\n",
    "\n",
    "print(ME_files)\n",
    "print(len(ME_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting down parameters for bruxism detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters set\n"
     ]
    }
   ],
   "source": [
    "#Setting parameters\n",
    "os.chdir(\"C:/Users/Zeta/Documents/acou_sommeil_HD_ENS/Tinnitus-n-Sleep/Notebooks\")\n",
    "THR_classif=[[0,2]]\n",
    "sfreq = 200\n",
    "window_length = 0.25                    # in seconds\n",
    "duration = int(window_length * sfreq)   # in samples\n",
    "interval = duration                     # no overlapping\n",
    "n_adaptive = 480 # number of epochs for adaptative baseline\n",
    "\n",
    "#Importing personnalized parameters for dataset\n",
    "df = pd.read_pickle(\"data/valid_chans_THR_imp.pk\")\n",
    "dico_chans= df.to_dict(\"list\")\n",
    "print(\"parameters set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bruxism + MEMA processing for pure MEMA visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed : \n",
      "1DA15_nuit_son.edf\n",
      "['1', '2']\n",
      "Bruxism reporting done\n",
      "Data filtered\n",
      "Epochs done, shape (32460, 1, 200)\n"
     ]
    }
   ],
   "source": [
    "filenames = ME_files[:1]  # load file from config\n",
    "#filenames=['E:/Acou_sommeil/EDF_V2_PAUL\\\\sophie_mema.edf']\n",
    "\n",
    "#Output of the processing, stock pure MEMA analysis output\n",
    "ME_reports={}\n",
    "results={}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    print(\"Files processed : \")\n",
    "    \n",
    "    #Loop on all the patient files\n",
    "    for filename in filenames:\n",
    "        \n",
    "        #-----------------Preparation for bruxism  processing ---------------------------------------\n",
    "        #opens the raw file\n",
    "        raw = mne.io.read_raw_edf(filename, preload=False, verbose=False)  # prepare loading\n",
    "        print(filename.split(\"\\\\\")[-1])\n",
    "        #Get channels indexes\n",
    "        ind_picks_chan= dico_chans[filename.split(\"\\\\\")[-1]][0]\n",
    "        ind_picks_imp= dico_chans[filename.split(\"\\\\\")[-1]][1]\n",
    "        #Get THR_imp value for filename\n",
    "        THR_imp = dico_chans[filename.split(\"\\\\\")[-1]][2]\n",
    "        #Get channel names from indexes\n",
    "        if len(ind_picks_chan)>0: #ignore file if no channel is good\n",
    "            picks_chan=[]\n",
    "            for elm in ind_picks_chan:\n",
    "                picks_chan.append(raw.info[\"ch_names\"][elm])\n",
    "            picks_imp=[]\n",
    "            for elm in ind_picks_imp:\n",
    "                picks_imp.append(raw.info[\"ch_names\"][elm])\n",
    "            print(picks_chan)\n",
    "            #Setting parameters for is_good\n",
    "            params = dict(ch_names=picks_chan,\n",
    "                  rejection_thresholds=dict(emg=1e-04),  # two order of magnitude higher q0.01\n",
    "                  flat_thresholds=dict(emg=1e-09),  # one order of magnitude lower median\n",
    "                  channel_type_idx=dict(emg=[ i for i in range(len(picks_chan))]),\n",
    "                  full_report=True\n",
    "                  )\n",
    "            #Epoching parameters\n",
    "            window_length = 0.25                    # in seconds\n",
    "            duration = int(window_length * sfreq)   # in samples\n",
    "            interval = duration                     # no overlapping\n",
    "            \n",
    "            \n",
    "            #-----------------Bruxism  processing ---------------------------------------\n",
    "            # Get the preprocessing steps done\n",
    "            epochs, valid_labels, log = preprocess(raw, picks_chan, picks_imp, duration, interval, \n",
    "                                                   params, THR_imp=THR_imp, get_log=True)\n",
    "            if np.sum(valid_labels)>0 : #If at least one epoch is good create report\n",
    "                results[filename] = reporting(epochs, valid_labels, THR_classif, n_adaptive, log)\n",
    "                #List of labels for MEMA processing crossing\n",
    "                bruxism = results[filename][\"labels\"][0]\n",
    "                artefacts = valid_labels\n",
    "            \n",
    "                print(\"Bruxism reporting done\")\n",
    "\n",
    "                #-----------------MEMA processing preparation ---------------------------------------\n",
    "                picks_chan = ['Airflow']           # middle ear electrode\n",
    "                raw  = CreateRaw(raw[picks_chan][0], picks_chan, ch_types=['emg']) # pick channels and load\n",
    "                ch_names = raw.info[\"ch_names\"]\n",
    "                print(\"Data filtered\")\n",
    "\n",
    "                #epoching\n",
    "                sfreq = raw.info[\"sfreq\"]\n",
    "                window_length = 1                    # in seconds\n",
    "                duration = int(window_length * sfreq)   # in samples\n",
    "                interval = duration                     # no overlapping\n",
    "                epochs = RawToEpochs_sliding(raw, duration=duration, interval=interval)\n",
    "                print(f\"Epochs done, shape {epochs.shape}\")\n",
    "\n",
    "                #-----------------MEMA processing Foward-backward ---------------------------------------\n",
    "                #Foward\n",
    "                # compute the sum of power over electrodes and samples in each window\n",
    "                pipeline = AmplitudeThresholding(abs_threshold=0., rel_threshold=4, n_adaptive=60)\n",
    "                X        = rms(epochs) # take only valid labels\n",
    "                labels_f   = pipeline.fit_predict(X)\n",
    "\n",
    "\n",
    "                #Backward\n",
    "                #Reversing epochs array\n",
    "                epochs = epochs[::-1]\n",
    "                 # compute the sum of power over electrodes and samples in each window\n",
    "                pipeline = AmplitudeThresholding(abs_threshold=0., rel_threshold=4, n_adaptive=60)\n",
    "                X        = rms(epochs) # take only valid labels\n",
    "                labels   = pipeline.fit_predict(X)\n",
    "                #Reversing labels\n",
    "                labels_b = labels[::-1]\n",
    "                \n",
    "                \n",
    "                #-----------------MEMA foward-backward merge and epochs length adaptation---------------------------------------\n",
    "                # Logical OR -- merged backward and foward\n",
    "                labels_fb = np.any(np.c_[labels_f, labels_b], axis=-1)\n",
    "                \n",
    "                #adaptation of labels_fb from 1s epochs to 0,25s epochs\n",
    "                labels_fb_shep=[]  \n",
    "                for elm in labels_fb:\n",
    "                    for i in range(4):\n",
    "                        labels_fb_shep.append(elm)\n",
    "                 \n",
    "                #-----------------Pure MEMA bursts conversion to episodes ----------------------------------------\n",
    "                OM_burst = classif_to_burst(labels_fb_shep, time_interval=0.25)\n",
    "                OM_ep= burst_to_episode(OM_burst, delim=2, min_burst_joining=0)\n",
    "                li_OM = create_list_events(OM_ep, 0.25, 0.25* len(bruxism))\n",
    "                \n",
    "                \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "400.0\n",
      "4265.0\n",
      "4271.0\n",
      "5903.0\n",
      "9503.0\n",
      "11364.0\n",
      "11417.0\n",
      "11694.0\n",
      "11742.0\n",
      "11745.0\n",
      "11752.0\n",
      "11757.0\n",
      "12755.0\n",
      "13061.0\n",
      "13863.0\n",
      "14111.0\n",
      "14343.0\n",
      "18444.0\n",
      "18776.0\n",
      "18950.0\n",
      "18956.0\n",
      "22966.0\n",
      "23059.0\n",
      "23063.0\n",
      "24076.0\n",
      "25143.0\n",
      "25231.0\n",
      "25252.0\n",
      "25509.0\n",
      "26972.0\n",
      "27015.0\n",
      "30979.0\n",
      "31576.0\n",
      "32383.0\n",
      "32415.0\n"
     ]
    }
   ],
   "source": [
    "print(len(OM_ep))\n",
    "for elm in OM_ep:\n",
    "    print(elm.beg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #-----------------MEMA / bruxism merge preparation---------------------------------------\n",
    "                \n",
    "                        \n",
    "                        \n",
    "                #Creation of the list of episodes from the labels list of bruxism:\n",
    "                burst_list = classif_to_burst(bruxism, time_interval=0.25)\n",
    "                li_ep = burst_to_episode(burst_list, delim=3)\n",
    "                event_list = create_list_events(li_ep, 0.25, len(bruxism) * 0.25)\n",
    "                #Careful, len(labels_fb_shep) and len(bruxism) maybe different by 1, 2 or 3 due to rounding effects.\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "                #-----------------MEMA / bruxism merge to obtain Pure MEMA -----------------------------------------------\n",
    "                #merge MEMA and compare with bruxism and artefacts\n",
    "                for i in range(len(bruxism)):\n",
    "                    if i < len(labels_fb_shep) - 1 : #len(labels_fb_shep) and len(bruxism) may be different by 1, 2 or 3\n",
    "                        if bruxism[i]:\n",
    "                            labels_fb_shep[i] = False\n",
    "                        if not artefacts[i]:\n",
    "                            labels_fb_shep[i] = False\n",
    "                        if not event_list[i] == 0:\n",
    "                            labels_fb_shep[i] = False\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                #All episodes as tonic\n",
    "                for elm in li_OM:\n",
    "                    if elm!=0:\n",
    "                        elm=True\n",
    "                    else:\n",
    "                        elm = False\n",
    "\n",
    "                #Should work without these lines since episode fix with min_burst_joining=0\n",
    "                miny = min(len(li_OM), len(labels_fb_shep))\n",
    "                MEMA = np.any(np.c_[li_OM[:miny], labels_fb_shep[:miny]], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "                print(\"number of middle ear events\")\n",
    "                print(len(OM_ep))\n",
    "                \n",
    "\n",
    "\n",
    "                #-----------------Pure MEMA episodes visualisation and comparison with ATM activity -----------------------------------\n",
    "                #Preparing raw for visualisation\n",
    "                picks_chan = ['Airflow', '1', '2']           # subset of EMG electrodes\n",
    "                raw  = mne.io.read_raw_edf(filename, preload=False, verbose=False)  # prepare loading\n",
    "                raw  = CreateRaw(raw[picks_chan][0], picks_chan, ch_types='emg')        # pick channels and load\n",
    "                raw  = raw.load_data()\n",
    "                dat=raw.get_data()\n",
    "                dat[1]=[dat[1][i]*1/(0.0005) for i in range(len(dat[1]))]\n",
    "                dat[2]=[dat[2][i]*1/(0.0005) for i in range(len(dat[2]))]\n",
    "                raw  = CreateRaw(dat, picks_chan, ch_types='emg') \n",
    "\n",
    "                raw  = raw.filter(20., 99., n_jobs=4, \n",
    "                                  fir_design='firwin', filter_length='auto', phase='zero-double',\n",
    "                                  picks=['1', '2'])\n",
    "                \n",
    "                #Annotating the raw\n",
    "                raw = CleanAnnotations(raw)\n",
    "                dict_annotations = {1: \"tot\"}\n",
    "                raw = AnnotateRaw_sliding(raw, MEMA, \n",
    "                                dict_annotations=dict_annotations, duration=50, interval=50)\n",
    "                print(\"Raw annotated\")\n",
    "                raw.plot(scalings = \"auto\")\n",
    "                plt.title(filename)\n",
    "                ME_reports[filename] = [MEMA, len(OM_ep), np.sum(MEMA)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Acou_sommeil/EDF_V2_PAUL\\1DA15_nuit_son.edf\n",
      "15\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\1GB19_nuit_hab.edf\n",
      "141\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\1MF19_nuit_hab.edf\n",
      "37\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\HZB_nuit_1.edf\n",
      "70\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\HZB_nuit_2.edf\n",
      "49\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\HZB_nuit_3.edf\n",
      "22\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf\n",
      "142\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHMIDTLIN_nuit_4_dec_OD__3to3.edf\n",
      "110\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHMIDTLIN_nuit_5_dec_OD__0to1.edf\n",
      "101\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHM_nuit_1.edf\n",
      "6\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHM_nuit_2.edf\n",
      "87\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\SCHM_nuit_3.edf\n",
      "147\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\Schmidtlin_nuit_2_dec_3to0to4.edf\n",
      "0\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\Unger_2.edf\n",
      "272\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\jon_mema.edf\n",
      "182\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\jose_mema.edf\n",
      "29\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\robin_mema_nuit_1.edf\n",
      "78\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\robin_mema_nuit_2.edf\n",
      "166\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\sophie_mema.edf\n",
      "130\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\tom_mema.edf\n",
      "89\n",
      "E:/Acou_sommeil/EDF_V2_PAUL\\unger_nuit_1.edf\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "for elm in ME_reports.keys():\n",
    "    print(elm)\n",
    "    print(ME_reports[elm][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small function to check if all channel selections are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed : \n",
      "1BA07_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1BA07_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1CC05_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1CC05_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1DA15_nuit_hab.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "1DA15_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1DL12_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1DL12_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1GB18_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1GB19_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1GF14_nuit_hab.edf\n",
      "1GF14_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MA16_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MA16_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MF19_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MF19_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1MN09_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1MN09_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1PI07_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1PI07_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1PT06_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1PT06_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1RA17_nuit_hab.edf\n",
      "1RA17_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1SA14_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1SA14_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "1ZN04_nuit_hab.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "1ZN04_nuit_son.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "HZB_nuit_1.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "HZB_nuit_2.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "HZB_nuit_3.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "SCHMIDTLIN_nuit_1_dec_OD__0to0.edf\n",
      "SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "SCHMIDTLIN_nuit_4_dec_OD__3to3.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "SCHMIDTLIN_nuit_5_dec_OD__0to1.edf\n",
      "['1']\n",
      "['1 Imp?dance']\n",
      "\n",
      "SCHM_nuit_1.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "SCHM_nuit_2.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "SCHM_nuit_3.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "Schmidtlin_nuit_2_dec_3to0to4.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "Unger_2.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "jon_mema.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "jose_mema.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "robin_mema_nuit_1.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "robin_mema_nuit_2.edf\n",
      "['1', '2']\n",
      "['1 Imp?dance', '2 Imp?dance']\n",
      "\n",
      "robin_nuit_23_sept.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "robin_nuit_son_24_sept.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n",
      "sophie_mema.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "tom_mema.edf\n",
      "['2']\n",
      "['2 Imp?dance']\n",
      "\n",
      "unger_nuit_1.edf\n",
      "['1', '2']\n",
      "['1 Impedance', '2 Impedance']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "labels_subj={}\n",
    "EDF_list = Config.bruxisme_files\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    results={}\n",
    "    print(\"Files processed : \")\n",
    "    for filename in EDF_list:\n",
    "        #opens the raw file\n",
    "        raw = mne.io.read_raw_edf(filename, preload=False, verbose=False)  # prepare loading\n",
    "        print(filename.split(\"\\\\\")[-1])\n",
    "        #Get channels indexes\n",
    "        ind_picks_chan= dico_chans[filename.split(\"\\\\\")[-1]][0]\n",
    "        ind_picks_imp= dico_chans[filename.split(\"\\\\\")[-1]][1]\n",
    "        #Get THR_imp value for filename\n",
    "        THR_imp = dico_chans[filename.split(\"\\\\\")[-1]][2]\n",
    "        #print(raw.info[\"ch_names\"])\n",
    "        #Get channel names from indexes\n",
    "        if len(ind_picks_chan)>0: #ignore file if no channel is good\n",
    "            picks_chan=[]\n",
    "            for elm in ind_picks_chan:\n",
    "                picks_chan.append(raw.info[\"ch_names\"][elm])\n",
    "            picks_imp=[]\n",
    "            for elm in ind_picks_imp:\n",
    "                picks_imp.append(raw.info[\"ch_names\"][elm])\n",
    "            print(picks_chan)\n",
    "            print(picks_imp)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
