{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-subject analysis\n",
    "\n",
    "This notebook will \n",
    "- Process and generate reports for all the dataset following procedure detailed in Bruxism detection\n",
    "- Display several metrics for all patients of the datasets\n",
    "- Display group analysis differences between tinnitus overnight increase patients and stable overnight patients (for tinnitus masking volume and VAS scales)\n",
    "- Display correlation plots between tinnitus evolution overnight and number of bruxisme episodes per hour (for tinnitus masking volume and VAS scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = os.getcwd() \n",
    "import sys\n",
    "sys.path.append(PATH + '/../')\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tinnsleep.config import Config\n",
    "from tinnsleep.create_reports import reporting\n",
    "from tinnsleep.data import RawToEpochs_sliding, CreateRaw\n",
    "from tinnsleep.scoring import generate_MEMA_report\n",
    "\n",
    "print(\"config loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters set\n",
      "['1DA15_nuit_son.edf' '1GB19_nuit_hab.edf' '1MF19_nuit_hab.edf']\n"
     ]
    }
   ],
   "source": [
    "#Setting parameters\n",
    "EDF_list = Config.bruxisme_files\n",
    "THR_classif=[[0,2.5], [0,3], [0,3.5], [0,4], [0,5], [0,6], [0,7]]\n",
    "sfreq = 250.0\n",
    "window_length = 1.00                    # in seconds\n",
    "duration = int(window_length * sfreq)   # in samples\n",
    "interval = duration                     # no overlapping\n",
    "n_adaptive = -60/window_length          # number of epochs for adaptive baseline\n",
    "delim = 3                               # maximal time interval between bursts to merge episode in seconds\n",
    "\n",
    "# Dictionnary of known names of the Airflow\n",
    "mapping = {\"Airflow\": \"MEMA\"}\n",
    "print(\"parameters set\")\n",
    "\n",
    "mema_files = pd.read_csv(\"data/mema_files.csv\",engine='python', sep=\"; \")[\"files_with_mema\"].values\n",
    "print(mema_files[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing of the dataset and report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed: \n",
      "1BA07_nuit_hab.edf not included\n",
      "1BA07_nuit_son.edf not included\n",
      "1CC05_nuit_hab.edf not included\n",
      "1CC05_nuit_son.edf not included\n",
      "1DA15_nuit_hab.edf not included\n",
      "1DA15_nuit_son.edf preprocess...DONE (0.34s) report...DONE (43.36s)\n",
      "1DL12_nuit_hab.edf not included\n",
      "1DL12_nuit_son.edf not included\n",
      "1GB18_nuit_son.edf not included\n",
      "1GB19_nuit_hab.edf preprocess...DONE (0.39s) report...DONE (47.55s)\n",
      "1GF14_nuit_hab.edf not included\n",
      "1GF14_nuit_son.edf not included\n",
      "1MF19_nuit_hab.edf preprocess...DONE (0.45s) report...DONE (42.75s)\n",
      "1MF19_nuit_son.edf not included\n",
      "1MN09_nuit_hab.edf not included\n",
      "1MN09_nuit_son.edf not included\n",
      "1PI07_nuit_hab.edf not included\n",
      "1PI07_nuit_son.edf not included\n",
      "1PT06_nuit_hab.edf not included\n",
      "1PT06_nuit_son.edf not included\n",
      "1RA17_nuit_hab.edf preprocess...DONE (0.86s) report...DONE (43.72s)\n",
      "1RA17_nuit_son.edf not included\n",
      "1SA14_nuit_hab.edf not included\n",
      "1SA14_nuit_son.edf not included\n",
      "1ZN04_nuit_hab.edf not included\n",
      "1ZN04_nuit_son.edf not included\n",
      "HZB_nuit_1.edf preprocess...DONE (0.26s) report...DONE (33.10s)\n",
      "HZB_nuit_2.edf preprocess...DONE (0.25s) report...DONE (35.92s)\n",
      "SCHM_nuit_2.edf preprocess...DONE (0.76s) report...DONE (44.04s)\n",
      "SCHM_nuit_3.edf preprocess...DONE (1.06s) report...DONE (62.23s)\n",
      "Unger_2.edf preprocess...DONE (0.84s) report...DONE (51.15s)\n",
      "jon_mema.edf preprocess...DONE (0.69s) report...DONE (58.97s)\n",
      "jose_mema.edf preprocess...DONE (0.47s) report...DONE (36.41s)\n",
      "robin_mema_nuit_1.edf preprocess...DONE (0.55s) report...DONE (39.64s)\n",
      "robin_mema_nuit_2.edf preprocess...DONE (0.51s) report...DONE (36.52s)\n",
      "sophie_mema.edf preprocess...DONE (0.52s) report...DONE (39.73s)\n",
      "tom_mema.edf preprocess...DONE (0.51s) report...DONE (39.79s)\n",
      "unger_nuit_1.edf preprocess...DONE (1.36s) report...DONE (73.15s)\n",
      "Reports created, process finished in 12.3 min\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from time import time\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    results={}\n",
    "    print(\"Files processed: \")\n",
    "    start = time()\n",
    "    for filename in EDF_list:\n",
    "        #opens the raw file\n",
    "        file = filename.split(os.path.sep)[-1]\n",
    "        print(file, end=\" \")\n",
    "        if file in mema_files:\n",
    "            #Get channels MEMA\n",
    "            raw = mne.io.read_raw_edf(filename, preload=False, verbose=False)  # prepare loading\n",
    "            raw.rename_channels(mapping=mapping)\n",
    "            picks_chan_user= ['MEMA']  # could be remplaced by an user-specific list loaded from .pk\n",
    "            ch_types = \"misc\"\n",
    "            #check if channels exists\n",
    "            picks_chan = [];[picks_chan.append(ch) for ch in picks_chan_user if ch in raw.info[\"ch_names\"]]\n",
    "\n",
    "            #Get channel names from indexes\n",
    "            if len(picks_chan)>0: #ignore file if no channel is good\n",
    "\n",
    "                #-----------------MEMA processing preparation ---------------------------------------\n",
    "                print(\"preprocess...\", end=\"\");tmp = time()\n",
    "                raw = CreateRaw(raw[picks_chan][0], raw.info[\"sfreq\"], picks_chan, ch_types=ch_types)  # pick channels and load\n",
    "                epochs = RawToEpochs_sliding(raw, duration=duration, interval=interval, picks=picks_chan)\n",
    "                print(f\"DONE ({time()-tmp:.2f}s)\", end=\" \")\n",
    "                valid_labels = [True] * epochs.shape[0] # consider all valid epochs\n",
    "                print(\"report...\", end=\"\");tmp = time()\n",
    "                results[filename] = reporting(epochs, valid_labels, THR_classif, time_interval=window_length, delim=delim, n_adaptive=n_adaptive, generate_report=generate_MEMA_report)\n",
    "                print(f\"DONE ({time()-tmp:.2f}s)\")\n",
    "            else:\n",
    "                print(f\"NO VALID CHANNEL\")\n",
    "        else:\n",
    "            print(f\"not included\")\n",
    "\n",
    "\n",
    "print(f\"Reports created, process finished in {(time()-start)/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results)\n",
    "df.to_pickle(\"data/reports_and_datas_MEMA.pk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization for the entire cohort for nb MEMA episodes per hour as a function of THR_classif value : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for elm in results.keys():\n",
    "    nb_ep=[]\n",
    "    get_r_THRs=[]\n",
    "    for th in results[elm][\"THR_classif\"]:\n",
    "        get_r_THRs.append(th[1])\n",
    "    for ep in results[elm][\"reports\"]:\n",
    "        nb_ep.append(ep[\"Number of MEMA episodes per hour\"])\n",
    "    st = elm.split(os.path.sep)[-1] + \" len \" + str(ep[\"Clean MEMA duration\"])\n",
    "    plt.plot(get_r_THRs, nb_ep)\n",
    "plt.title('Comparison for all subjects for nb of MEMA episodes per hour')\n",
    "plt.xlabel('THR_classif value')\n",
    "plt.ylabel('Nb of episodes per hour')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization for the entire cohort for nb MEMA bursts as a function of THR_classif value : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for elm in results.keys():\n",
    "    nb_ep=[]\n",
    "    get_r_THRs=[]\n",
    "    for th in results[elm][\"THR_classif\"]:\n",
    "        get_r_THRs.append(th[1])\n",
    "    for ep in results[elm][\"reports\"]:\n",
    "        nb_ep.append(ep[\"Total number of MEMA burst\"])\n",
    "    #print(f\"Number of bursts for each THR_classif for {elm[-19:]} : {nb_ep}\")\n",
    "    st = elm.split(os.path.sep)[-1] + \" len \" + str(ep[\"Clean MEMA duration\"])\n",
    "    plt.plot(get_r_THRs, nb_ep)\n",
    "plt.title('Comparison for all subjects on total number of MEMA bursts')\n",
    "plt.xlabel('THR_classif value')\n",
    "plt.ylabel('Nb of MEMA burst on the recording')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting list of nb of episodes per hour for all THR_classif per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores=[]\n",
    "for elm in results.keys():\n",
    "        #print (elm)\n",
    "        l_ep_h=[]\n",
    "        for ep in results[elm][\"reports\"]:\n",
    "            l_ep_h.append(ep[\"Number of MEMA episodes per hour\"])\n",
    "\n",
    "        get_scores.append([elm.split(os.path.sep)[-1], l_ep_h])\n",
    "print(len(get_scores))\n",
    "print(get_scores[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting masking, VAS-Loudness and  VAS-Intrusiveness data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_masking = pd.read_csv(\"data/evol_masquage.csv\", delimiter=\";\")\n",
    "#print(get_masking)\n",
    "get_VAS_L = pd.read_csv(\"data/evol_eva_I.csv\", delimiter=\";\")\n",
    "#print(get_VAS_L)\n",
    "get_VAS_I = pd.read_csv(\"data/evol_eva_G.csv\", delimiter=\";\")\n",
    "#print(get_VAS_I)\n",
    "\n",
    "evol_masking = get_masking.values.tolist()[:-4]\n",
    "evol_VAS_L = get_VAS_L.values.tolist()\n",
    "evol_VAS_I = get_VAS_I.values.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing nb_ep/hour between patients with tinnitus increase (augm) and without (stable) for values of THR_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files not to consider for analysis\n",
    "to_suppress=[\"1MA16_nuit_hab.edf\",\"SCHM_nuit_1.edf\",\"HZB_nuit_3.edf\"]\n",
    "#Jutification : \"Schmidtlin_nuit_2_dec_3to0to4.edf\", \"SCHMIDTLIN_nuit_1_dec_OD__0to0.edf\", \n",
    "# \"SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf\" : compromised data\n",
    "# 1MA16_nuit_hab : patient awake all night\n",
    "# HZB_nuit_3.edf partial night \n",
    "\n",
    "#Preparing values for correlation scatter plots\n",
    "scat=[[] for i in range(len(THR_classif))]  #scatter plots with absolute values\n",
    "pourc_scat=[[] for i in range(len(THR_classif))]  #scatter plots with percentages values\n",
    "\n",
    "\n",
    "augm=[[] for i in range(len(THR_classif))]  #patients with tinnitus increase\n",
    "stable=[[] for i in range(len(THR_classif))] #patients with stable or decreasing tinnitus\n",
    "for elm in evol_masking:\n",
    "    for i in range(len(get_scores)):\n",
    "     if not to_suppress.__contains__(elm[0]):\n",
    "        if elm[0]==get_scores[i][0]:\n",
    "            \n",
    "            #For correlation scatter plots\n",
    "            for j in range(len(THR_classif)):\n",
    "                #getting points [abs evolution masking volume ; coreesponding nb_episode/hour]\n",
    "                scat[j].append([elm[-2], get_scores[i][1][j]])\n",
    "                if elm[-1] < 1 :  # removing a strong outlier\n",
    "                    #getting points [% evolution masking volume ; coreesponding nb_episode/hour]\n",
    "                    pourc_scat[j].append([elm[-1], get_scores[i][1][j]])\n",
    "            \n",
    "            #Sorting patients according to tinnitus evolution overnight\n",
    "            if (elm[2]>0):\n",
    "                for j in range(len(THR_classif)):\n",
    "                    augm[j].append(get_scores[i][1][j])\n",
    "            else:\n",
    "                for j in range(len(THR_classif)):\n",
    "                    stable[j].append(get_scores[i][1][j])\n",
    "                    \n",
    "#Calculating mean and standard deviation for all THR_classif values\n",
    "augm_m=[]\n",
    "augm_std=[]\n",
    "stable_m=[]\n",
    "stable_std=[]\n",
    "for elm in augm:\n",
    "    augm_m.append(np.mean(elm))\n",
    "    augm_std.append(np.std(elm))\n",
    "for elm in stable:\n",
    "    stable_m.append(np.mean(elm))\n",
    "    stable_std.append(np.std(elm))\n",
    "    \n",
    "print(\"Nb_patients in each group : \")\n",
    "print(\"Tinnitus increase : \" + str(len(augm[0])))\n",
    "print(\"Tinnitus stable : \" + str(len(stable[0])))\n",
    "    \n",
    "#Displaying\n",
    "plt.figure()\n",
    "plt.errorbar([i+2 for i in range(len(THR_classif))],stable_m, stable_std)\n",
    "plt.errorbar([i+2 for i in range(len(THR_classif))], augm_m, augm_std)\n",
    "plt.title(\"Comparing nb_episodes/hour (y) between patients with (or) \\n and without (bl) tinnitus increase for masking\" )\n",
    "plt.xlabel('THR_classif value')\n",
    "plt.ylabel('Nb of episodes per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying correlation plots for absolute overnight evolutions of tinnitus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in range(len(THR_classif)):  \n",
    "    tab = np.asanyarray(scat[j])\n",
    "    tab = tab.transpose()\n",
    "    #print(j+2)\n",
    "    \n",
    "    regre = scipy.stats.linregress(tab[0],tab[1])\n",
    "    #print(regre)\n",
    "    slope=regre[0]\n",
    "    intercept = regre[1]\n",
    "    plt.figure()\n",
    "    plt.scatter(tab[0], tab[1])\n",
    "    plt.plot([i-25 for i in range(40)],[intercept + slope *(i-25) for i in range(40)])\n",
    "    #plt.plot([i-1 for i in range(3)],[intercept + slope *(i-1) for i in range(3)])\n",
    "    plt.title(\"Correlation attempt for THR_classif of \" + str(j+2) + \" with p_val \"+ str(\"%.3f\" % regre[3]))\n",
    "    plt.xlabel('(Morning masking volume) - (night masking volume) ')\n",
    "    plt.ylabel('Nb of episodes per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying correlation plots for percentage overnight evolutions of tinnitus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(THR_classif)):\n",
    "    tab = np.asanyarray(pourc_scat[j])\n",
    "    tab = tab.transpose()\n",
    "    regre = scipy.stats.linregress(tab[0],tab[1])\n",
    "    slope=regre[0]\n",
    "    intercept = regre[1]\n",
    "    plt.figure()\n",
    "    plt.scatter(tab[0], tab[1])\n",
    "    plt.plot([i-1 for i in range(3)],[intercept + slope *(i-1) for i in range(3)])\n",
    "    plt.title(\"Correlation attempt for THR_classif of \" + str(j+2) + \" with p_val \"+ str(\"%.3f\" % regre[3]))\n",
    "    plt.xlabel('(Morning masking volume) - (night masking volume) / (night masking volume) ')\n",
    "    plt.ylabel('Nb of episodes per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAS-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files not to consider for analysis\n",
    "to_suppress=[\"Schmidtlin_nuit_2_dec_3to0to4.edf\", \"SCHMIDTLIN_nuit_1_dec_OD__0to0.edf\",\n",
    "             \"SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf\",\"1MA16_nuit_hab.edf\",\"SCHM_nuit_1.edf\",\n",
    "             \"HZB_nuit_3.edf\"]\n",
    "#Jutification : \"Schmidtlin_nuit_2_dec_3to0to4.edf\", \"SCHMIDTLIN_nuit_1_dec_OD__0to0.edf\", \n",
    "# \"SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf\" : compromised data\n",
    "# 1MA16_nuit_hab : patient awake all night\n",
    "# HZB_nuit_3.edf partial night \n",
    "\n",
    "#Preparing values for correlation scatter plots\n",
    "scat=[[] for i in range(len(THR_classif))]  #scatter plots with absolute values\n",
    "pourc_scat=[[] for i in range(len(THR_classif))]  #scatter plots with percentages values\n",
    "\n",
    "\n",
    "augm=[[] for i in range(len(THR_classif))]  #patients with tinnitus increase\n",
    "stable=[[] for i in range(len(THR_classif))] #patients with stable or decreasing tinnitus\n",
    "for elm in evol_VAS_L:\n",
    "    for i in range(len(get_scores)):\n",
    "     if not to_suppress.__contains__(elm[0]):\n",
    "        if elm[0]==get_scores[i][0]:\n",
    "            \n",
    "            #For correlation scatter plots\n",
    "            for j in range(len(THR_classif)):\n",
    "                #getting points [abs evolution masking volume ; coreesponding nb_episode/hour]\n",
    "                scat[j].append([elm[-2], get_scores[i][1][j]])\n",
    "                if elm[-1] < 1 :  # removing a strong outlier\n",
    "                    #getting points [% evolution masking volume ; coreesponding nb_episode/hour]\n",
    "                    pourc_scat[j].append([elm[-1], get_scores[i][1][j]])\n",
    "            \n",
    "            #Sorting patients according to tinnitus evolution overnight\n",
    "            if (elm[2]>0):\n",
    "                for j in range(len(THR_classif)):\n",
    "                    augm[j].append(get_scores[i][1][j])\n",
    "            else:\n",
    "                for j in range(len(THR_classif)):\n",
    "                    stable[j].append(get_scores[i][1][j])\n",
    "                    \n",
    "#Calculating mean and standard deviation for all THR_classif values\n",
    "augm_m=[]\n",
    "augm_std=[]\n",
    "stable_m=[]\n",
    "stable_std=[]\n",
    "for elm in augm:\n",
    "    augm_m.append(np.mean(elm))\n",
    "    augm_std.append(np.std(elm))\n",
    "for elm in stable:\n",
    "    stable_m.append(np.mean(elm))\n",
    "    stable_std.append(np.std(elm))\n",
    "    \n",
    "print(\"Nb_patients in each group : \")\n",
    "print(\"Tinnitus increase : \" + str(len(augm[0])))\n",
    "print(\"Tinnitus stable : \" + str(len(stable[0])))\n",
    "    \n",
    "#Displaying\n",
    "plt.figure()\n",
    "plt.errorbar([i+2 for i in range(len(THR_classif))],stable_m, stable_std)\n",
    "plt.errorbar([i+2 for i in range(len(THR_classif))], augm_m, augm_std)\n",
    "plt.title(\"Comparing nb_episodes/hour (y) between patients with (or) \\n and without (bl) tinnitus increase for VAS_L\" )\n",
    "plt.xlabel('THR_classif value')\n",
    "plt.ylabel('Nb of episodes per hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(THR_classif)):  \n",
    "    tab = np.asanyarray(scat[j])\n",
    "    tab = tab.transpose()\n",
    "    #print(j+2)\n",
    "    \n",
    "    regre = scipy.stats.linregress(tab[0],tab[1])\n",
    "    #print(regre)\n",
    "    slope=regre[0]\n",
    "    intercept = regre[1]\n",
    "    plt.figure()\n",
    "    plt.scatter(tab[0], tab[1])\n",
    "    plt.plot([i-7 for i in range(14)],[intercept + slope *(i-7) for i in range(14)])\n",
    "    #plt.plot([i-1 for i in range(3)],[intercept + slope *(i-1) for i in range(3)])\n",
    "    plt.title(\"Correlation attempt for THR_classif of \" + str(j+2) + \" with p_val \"+ str(\"%.3f\" % regre[3]))\n",
    "    plt.xlabel('(Morning VAS_L after) - (morning VAS_L before) ')\n",
    "    plt.ylabel('Nb of episodes per hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(THR_classif)):\n",
    "    tab = np.asanyarray(pourc_scat[j])\n",
    "    tab = tab.transpose()\n",
    "    regre = scipy.stats.linregress(tab[0],tab[1])\n",
    "    slope=regre[0]\n",
    "    intercept = regre[1]\n",
    "    plt.figure()\n",
    "    plt.scatter(tab[0], tab[1])\n",
    "    plt.plot([i-1 for i in range(3)],[intercept + slope *(i-1) for i in range(3)])\n",
    "    plt.title(\"Correlation attempt for THR_classif of \" + str(j+2) + \" with p_val \"+ str(\"%.3f\" % regre[3]))\n",
    "    plt.xlabel('(Morning VAS_L after) - (morning VAS_L before) / (morning VAS_L before) ')\n",
    "    plt.ylabel('Nb of episodes per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAS_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files not to consider for analysis\n",
    "to_suppress=[\"Schmidtlin_nuit_2_dec_3to0to4.edf\", \"SCHMIDTLIN_nuit_1_dec_OD__0to0.edf\",\n",
    "             \"SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf\",\"1MA16_nuit_hab.edf\",\"SCHM_nuit_1.edf\",\n",
    "             \"HZB_nuit_3.edf\"]\n",
    "#Jutification : \"Schmidtlin_nuit_2_dec_3to0to4.edf\", \"SCHMIDTLIN_nuit_1_dec_OD__0to0.edf\", \n",
    "# \"SCHMIDTLIN_nuit_3_dec_OD__4to0to2.edf\" : compromised data\n",
    "# 1MA16_nuit_hab : patient awake all night\n",
    "# HZB_nuit_3.edf partial night \n",
    "\n",
    "#Preparing values for correlation scatter plots\n",
    "scat=[[] for i in range(len(THR_classif))]  #scatter plots with absolute values\n",
    "pourc_scat=[[] for i in range(len(THR_classif))]  #scatter plots with percentages values\n",
    "\n",
    "\n",
    "augm=[[] for i in range(len(THR_classif))]  #patients with tinnitus increase\n",
    "stable=[[] for i in range(len(THR_classif))] #patients with stable or decreasing tinnitus\n",
    "for elm in evol_VAS_I:\n",
    "    for i in range(len(get_scores)):\n",
    "     if not to_suppress.__contains__(elm[0]):\n",
    "        if elm[0]==get_scores[i][0]:\n",
    "            \n",
    "            #For correlation scatter plots\n",
    "            for j in range(len(THR_classif)):\n",
    "                #getting points [abs evolution masking volume ; coreesponding nb_episode/hour]\n",
    "                scat[j].append([elm[-2], get_scores[i][1][j]])\n",
    "                if elm[-1] < 1 :  # removing a strong outlier\n",
    "                    #getting points [% evolution masking volume ; coreesponding nb_episode/hour]\n",
    "                    pourc_scat[j].append([elm[-1], get_scores[i][1][j]])\n",
    "            \n",
    "            #Sorting patients according to tinnitus evolution overnight\n",
    "            if (elm[2]>0):\n",
    "                for j in range(len(THR_classif)):\n",
    "                    augm[j].append(get_scores[i][1][j])\n",
    "            else:\n",
    "                for j in range(len(THR_classif)):\n",
    "                    stable[j].append(get_scores[i][1][j])\n",
    "                    \n",
    "#Calculating mean and standard deviation for all THR_classif values\n",
    "augm_m=[]\n",
    "augm_std=[]\n",
    "stable_m=[]\n",
    "stable_std=[]\n",
    "for elm in augm:\n",
    "    augm_m.append(np.mean(elm))\n",
    "    augm_std.append(np.std(elm))\n",
    "for elm in stable:\n",
    "    stable_m.append(np.mean(elm))\n",
    "    stable_std.append(np.std(elm))\n",
    "    \n",
    "print(\"Nb_patients in each group : \")\n",
    "print(\"Tinnitus increase : \" + str(len(augm[0])))\n",
    "print(\"Tinnitus stable : \" + str(len(stable[0])))\n",
    "    \n",
    "#Displaying\n",
    "plt.figure()\n",
    "plt.errorbar([i+2 for i in range(len(THR_classif))],stable_m, stable_std)\n",
    "plt.errorbar([i+2 for i in range(len(THR_classif))], augm_m, augm_std)\n",
    "plt.title(\"Comparing nb_episodes/hour (y) between patients with (or) \\n and without (bl) tinnitus increase for VAS_L\" )\n",
    "plt.xlabel('THR_classif value')\n",
    "plt.ylabel('Nb of episodes per hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(THR_classif)):  \n",
    "    tab = np.asanyarray(scat[j])\n",
    "    tab = tab.transpose()\n",
    "    #print(j+2)\n",
    "    \n",
    "    regre = scipy.stats.linregress(tab[0],tab[1])\n",
    "    #print(regre)\n",
    "    slope=regre[0]\n",
    "    intercept = regre[1]\n",
    "    plt.figure()\n",
    "    plt.scatter(tab[0], tab[1])\n",
    "    plt.plot([i-7 for i in range(14)],[intercept + slope *(i-7) for i in range(14)])\n",
    "    #plt.plot([i-1 for i in range(3)],[intercept + slope *(i-1) for i in range(3)])\n",
    "    plt.title(\"Correlation attempt for THR_classif of \" + str(j+2) + \" with p_val \"+ str(\"%.3f\" % regre[3]))\n",
    "    plt.xlabel('(Morning VAS_I after) - (morning VAS_I before) ')\n",
    "    plt.ylabel('Nb of episodes per hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(THR_classif)):\n",
    "    tab = np.asanyarray(pourc_scat[j])\n",
    "    tab = tab.transpose()\n",
    "    regre = scipy.stats.linregress(tab[0],tab[1])\n",
    "    slope=regre[0]\n",
    "    intercept = regre[1]\n",
    "    plt.figure()\n",
    "    plt.scatter(tab[0], tab[1])\n",
    "    plt.plot([i-1 for i in range(3)],[intercept + slope *(i-1) for i in range(3)])\n",
    "    plt.title(\"Correlation attempt for THR_classif of \" + str(j+2) + \" with p_val \"+ str(\"%.3f\" % regre[3]))\n",
    "    plt.xlabel('(Morning VAS_I after) - (morning VAS_I before) / (morning VAS_I before) ')\n",
    "    plt.ylabel('Nb of episodes per hour')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinnsleep-env",
   "language": "python",
   "name": "tinnsleep-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
